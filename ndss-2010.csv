conference,title,abstract
symp2010,Server-side Verification of Client Behavior in Online Games,"Online gaming is a lucrative and growing industry, butone that is slowed by cheating that compromises the gamingexperience and hence drives away players (and revenues).In this paper we develop a technique by which game de-velopers can enable game operators to validate the behav-ior of game clients as being consistent with valid execu-tion of the sanctioned client software. Our technique em-ploys symbolic execution of the client software to extractconstraints on client-side state implied by each client-to-server message, and then uses constraint solving to deter-mine whether the sequence of client-to-server messages canbe “explained” by any possible user inputs, in light of theserver-to-client messages already received. The requisiteconstraints and solving components can be developed ei-ther simultaneously with the game or retroactively for ex-isting games. We demonstrate our approach in two casestudies: one of the open-source game XPilot, and one of agame similar to Pac-Man of our own design."
symp2010,Defeating Vanish with Low-Cost Sybil Attacks Against Large DHTs,"Researchers at the University of Washington recently pro-posed Vanish [20], a system for creating messages that au-tomatically “self-destruct” after a period of time. Vanishworks by encrypting each message with a random key andstoring shares of the key in a large, public distributed hashtable (DHT). DHTs expunge data older than a certain age;after this happens to the key shares, the key is permanentlylost, and the encrypted data is permanently unreadable. Van-ish is an interesting approach to an important privacy prob-lem, but, in its current form, it is insecure. In this paper,we defeat the deployed Vanish implementation, explain howthe original paper’s security analysis is flawed, and drawlessons for future system designs.We present two Sybil attacks against the current Van-ish implementation, which stores its encryption keys in themillion-node Vuze BitTorrent DHT. These attacks work bycontinuously crawling the DHT and saving each stored valuebefore it ages out. They can efficiently recover keys for morethan 99% of Vanish messages. We show that the dominantcost of these attacks is network data transfer, not memory us-age as the Vanish authors expected, and that the total cost istwo orders of magnitude less than they estimated. While weconsider potential defenses, we conclude that public DHTslike Vuze probably cannot provide strong security for Vanish.† Both authors contributed equally."
symp2010,Stealth DoS Attacks on Secure Channels,"We initiate study of the use of ‘secure tunnel’ proto-cols, specifically IPsec, and its availability and perfor-mance guarantees to higher-layer protocols, in particularTCP, against Denial/Degradation of Service (DoS) attacks.IPsec is designed to provide privacy and authenticationagainst MITM attackers, and employs an anti-replay mech-anism to ensure performance. For our analysis, we definea new family of adversaries, the stealth denial and degra-dation of service (DoS) adversaries. These adversaries areweaker than the classical MITM adversary, and may be ofinterest in other works. We analyse their ability to launch(DoS) attacks on secure channels, and show realistic am-plification attacks, disrupting TCP communication over se-cure VPNs using IPsec. In particular, we show that anti-replay mechanism is critical for performance by launchinga DoS attack on communication over IPsec without anti-replay window. We present attacks exploiting insufficientIPsec anti-replay window size, and show how to calculatecorrect window size. Finally we present attacks on IPsecwith correctly adjusted anti-replay window size thus show-ing that even large anti-replay window does not ensure per-formance to TCP flows. We then suggest a fix to TCP inIPsec gateway designed to prevent the above attacks, andto provide secure channel immune to degradation and otherDoS attacks. Our solution involves changes (only) to thesending gateway machines running IPsec. In addition totheir practical importance, our results also raise the chal-lenge of formally defining secure channels immune to DoSand degradation attacks, and providing provably-secure im-plementations.∗Amir.Herzberg@gmail.com†Haya.Shulman@gmail.com1."
symp2010,Protecting Browsers from Extension Vulnerabilities,"Browser extensions are remarkably popular, with one inthree Firefox users running at least one extension. Althoughwell-intentioned, extension developers are often not securityexperts and write buggy code that can be exploited by ma-licious web site operators. In the Firefox extension system,these exploits are dangerous because extensions run withthe user’s full privileges and can read and write arbitraryfiles and launch new processes. In this paper, we analyze25 popular Firefox extensions and find that 88% of theseextensions need less than the full set of available privileges.Additionally, we find that 76% of these extensions use un-necessarily powerful APIs, making it difficult to reduce theirprivileges. We propose a new browser extension system thatimproves security by using least privilege, privilege separa-tion, and strong isolation. Our system limits the misdeedsan attacker can perform through an extension vulnerabil-ity. Our design has been adopted as the Google Chromeextension system."
symp2010,Adnostic: Privacy Preserving Targeted Advertising,"Online behavioral advertising (OBA) refers to the prac-tice of tracking users across web sites in order to infer userinterests and preferences. These interests and preferencesare then used for selecting ads to present to the user. Thereis great concern that behavioral advertising in its presentform infringes on user privacy. The resulting public de-bate — which includes consumer advocacy organizations,professional associations, and government agencies — ispremised on the notion that OBA and privacy are inherentlyin conflict.In this paper we propose a practical architecture thatenables targeting without compromising user privacy. Be-havioral profiling and targeting in our system takes place inthe user’s browser. We discuss the effectiveness of the sys-tem as well as potential social engineering and web-basedattacks on the architecture. One complication is billing; ad-networks must bill the correct advertiser without knowingwhich ad was displayed to the user. We propose an efficientcryptographic billing system that directly solves the prob-lem. We implemented the core targeting system as a Firefoxextension and report on its effectiveness."
symp2010,FLAX: Systematic Discovery of Client-side Validation Vulnerabilities in Rich Web Applications,"The complexity of the client-side components of webapplications has exploded with the increase in popularityof web 2.0 applications. Today, traditional desktop ap-plications, such as document viewers, presentation toolsand chat applications are commonly available as onlineJavaScript applications.Previous research on web vulnerabilities has primarilyconcentrated on flaws in the server-side components of webapplications. This paper highlights a new class of vulnera-bilities, which we term client-side validation (or CSV) vul-nerabilities. CSV vulnerabilities arise from unsafe usage ofuntrusted data in the client-side code of the web applica-tion that is typically written in JavaScript. In this paper,we demonstrate that they can result in a broad spectrum ofattacks. Our work provides empirical evidence that CSVvulnerabilities are not merely conceptual but are prevalentin today’s web applications.We propose dynamic analysis techniques to systemati-cally discover vulnerabilities of this class. The techniquesare light-weight, efficient, and have no false positives. Weimplement our techniques in a prototype tool called FLAX,which scales to real-world applications and has discovered11 vulnerabilities in the wild so far."
symp2010,Effective Anomaly Detection with Scarce Training Data,"Learning-based anomaly detection has proven to bean effective black-box technique for detecting unknownattacks. However, the effectiveness of this techniquecrucially depends upon both the quality and the com-pleteness of the training data. Unfortunately, in mostcases, the traffic to the system (e.g., a web applica-tion or daemon process) protected by an anomaly de-tector is not uniformly distributed. Therefore, somecomponents (e.g., authentication, payments, or contentpublishing) might not be exercised enough to train ananomaly detection system in a reasonable time frame.This is of particular importance in real-world settings,where anomaly detection systems are deployed with lit-tle or no manual configuration, and they are expected toautomatically learn the normal behavior of a system todetect or block attacks.In this work, we first demonstrate that the featuresutilized to train a learning-based detector can be se-mantically grouped, and that features of the same grouptend to induce similar models. Therefore, we proposeaddressing local training data deficiencies by exploitingclustering techniques to construct a knowledge base ofwell-trained models that can be utilized in case of un-dertraining. Our approach, which is independent of theparticular type of anomaly detector employed, is vali-dated using the realistic case of a learning-based systemprotecting a pool of web servers running several webapplications such as blogs, forums, or Web services. Werun our experiments on a real-world data set containingover 58 million HTTP requests to more than 36,000 dis-tinct web application components. The results show thatby using the proposed solution, it is possible to achieveeffective attack detection even with scarce training data.Keywords: Anomaly detection, training data, web appli-cation."
symp2010,Large-Scale Automatic Classification of Phishing Pages,"Phishing websites, fraudulent sites that impersonate atrusted third party to gain access to private data, continueto cost Internet users over a billion dollars each year. Inthis paper, we describe the design and performance char-acteristics of a scalable machine learning classifier we de-veloped to detect phishing websites. We use this classifierto maintain Google’s phishing blacklist automatically. Ourclassifier analyzes millions of pages a day, examining theURL and the contents of a page to determine whether ornot a page is phishing. Unlike previous work in this field,we train the classifier on a noisy dataset consisting of mil-lions of samples from previously collected live classificationdata. Despite the noise in the training data, our classifierlearns a robust model for identifying phishing pages whichcorrectly classifies more than 90% of phishing pages sev-eral weeks after training concludes."
symp2010,A Systematic Characterization of IM Threats using Honeypots,"The popularity of instant messaging (IM) services hasrecently attracted the interest of attackers that try to sendmalicious URLs or files to the contact lists of compro-mised instant messaging accounts or clients. This workfocuses on a systematic characterization of IM threatsbased on the information collected by HoneyBuddy, ahoneypot-like infrastructure for detecting malicious ac-tivities in IM networks. HoneyBuddy finds and addscontacts to its honeypot messengers by querying pop-ular search engines for IM contacts or by advertisingits accounts on contact finder sites. Our deploymenthas shown that with over six thousand contacts we cangather between 50 and 110 malicious URLs per day aswell as executables. Our experiments show that 21% ofour collected executable samples were not gathered byother malware collection infrastructures, while 93% ofthe identified IM phishing domains were not recorded bypopular blacklist mechanisms. Furthermore, our find-ings show that the malicious domains are hosted bya limited number of hosts that remain practically un-changed throughout time."
symp2010,On Network-level Clusters for Spam Detection,"IP-based blacklist is an effective way to filter spamemails. However, building and maintaining individualIP addresses in the blacklist is difficult, as new mali-cious hosts continuously appear and their IP addressesmay also change over time. To mitigate this problem,researchers have proposed to replace individual IP ad-dresses in the blacklist with IP clusters, e.g., BGP clus-ters. In this paper, we closely examine the accuracy ofIP-cluster-based approaches to understand their effec-tiveness and fundamental limitations. Based on suchunderstanding, we propose and implement a new clus-tering approach that considers both network origin andDNS information, and incorporate it with SpamAssas-sin, a popular spam filtering system widely used today.Applying our approach to a 7-month email trace col-lected at a large university department, we can reducethe false negative rate by 50% compared with directlyapplying various public IP-based blacklists without in-creasing the false positive rate. Furthermore, using hon-eypot email accounts and real user accounts, we showthat our approach can capture 30% - 50% of the spamemails that slip through SpamAssassin today."
symp2010,Improving Spam Blacklisting Through Dynamic Thresholding and Speculative Aggregation,"Unsolicited bulk e-mail (UBE) or spam constitutes a sig-nificant fraction of all e-mail connection attempts and rou-tinely frustrates users, consumes resources, and serves asan infection vector for malicious software. In an effort toscalably and effectively reduce the impact of these e-mails,e-mail system designers have increasingly turned to black-listing. Blacklisting (blackholing, block listing) is a form ofcourse-grained, reputation-based, dynamic policy enforce-ment in which real-time feeds of spam sending hosts are sentto networks so that the e-mail from these hosts may be re-jected. Unfortunately, current spam blacklist services arehighly inaccurate and exhibit both false positives and sig-nificant false negatives. In this paper, we explore the rootcauses of blacklist inaccuracy and show that the trend to-ward stealthier spam exacerbates the existing tension be-tween false positives and false negatives when assigningspamming IP reputation. We argue that to relieve this ten-sion, global aggregation and reputation assignment shouldbe replaced with local aggregation and reputation assign-ment, utilizing preexisting global spam collection, with theaddition of local usage, policy, and reachability informa-tion. We propose two specific techniques based on thispremise, dynamic thresholding and speculative aggregation,whose goal is to improve the accuracy of blacklist genera-tion. We evaluate the performance and accuracy of thesesolutions in the context of our own deployment consisting of2.5 million production e-mails and 14 million e-mails fromspamtraps deployed in 11 domains over a month-long pe-riod. We show that the proposed approaches significantlyimprove the false positive and false negative rates whencompared to existing approaches."
symp2010,Botnet Judo: Fighting Spam with Itself,"We have traditionally viewed spam from the receiver’spoint of view: mail servers assaulted by a barrage of spamfrom which we must pick out a handful of legitimate mes-sages. In this paper we describe a system for better filteringspam by exploiting the vantage point of the spammer. Byinstantiating and monitoring botnet hosts in a controlledenvironment, we are able to monitor new spam as it is cre-ated, and consequently infer the underlying template usedto generate polymorphic e-mail messages. We demonstratethis approach on mail traces from a range of modern bot-nets and show that we can automatically filter such spamprecisely and with virtually no false positives."
symp2010,Contractual Anonymity,"We propose, develop, and implement techniques forachieving contractual anonymity. In contractual anon-ymity, a user and service provider enter into an anonym-ity contract. The user is guaranteed anonymity and mes-sage unlinkability from the contractual anonymity sys-tem unless she breaks the contract. The service provideris guaranteed that it can identify users who break thecontract. The significant advantages of our system arethat 1) the service provider is not able to take any actiontoward a particular user (such as revealing her identityor blacklisting her future authentications) unless she vi-olates her contract, 2) our system can enforce a varietyof policies, and 3) our system is efficient."
symp2010,A3: An Extensible Platform for Application-Aware Anonymity,"This paper presents the design and implementation ofApplication-Aware Anonymity (A3), an extensible plat-form for deploying anonymity-based services on the In-ternet. A3 allows applications to tailor their anonymityproperties and performance characteristics according tospecific communication requirements.To support flexible path construction, A3 exposes adeclarative language (A3LOG) that enables applicationsto compactly specify path selection and instantiationpolicies executed by a declarative networking engine.We demonstrate that our declarative language is suffi-ciently expressive to encode novel multi-metric perfor-mance constraints as well as existing relay selectionalgorithms employed by Tor and other anonymity sys-tems, using only a few lines of concise code. We exper-imentally evaluate the A3 system using a combinationof trace-driven simulations and deployment on Planet-Lab. Our experimental results demonstrate that A3 canflexibly support a wide range of path selection and in-stantiation strategies at low performance overhead."
symp2010,When Good Randomness Goes Bad: Virtual Machine Reset Vulnerabilities and Hedging Deployed Cryptography,"Random number generators (RNGs) are consistently aweak link in the secure use of cryptography. Routine cryp-tographic operations such as encryption and signing canfail spectacularly given predictable or repeated random-ness, even when using good long-lived key material. Thishas proved problematic in prior settings when RNG imple-mentation bugs, poor design, or low-entropy sources haveresulted in predictable randomness. We investigate a newway in which RNGs fail due to reuse of virtual machine(VM) snapshots. We exhibit such VM reset vulnerabilitiesin widely-used TLS clients and servers: the attacker takesadvantage of (or forces) snapshot replay to compromisesessions or even expose a server’s DSA signing key. Ournext contribution is a backwards-compatible framework forhedging routine cryptographic operations against bad ran-domness, thereby mitigating the damage due to randomnessfailures. We apply our framework to the OpenSSL libraryand experimentally confirm that it has little overhead."
symp2010,InvisiType: Object-Oriented Security Policies,"Many modern software platforms today, includingbrowsers, middleware server architectures, cell phone op-erating systems, web application engines, support third-party software extensions. This paper proposes InvisiType,an object-oriented approach that enables platform develop-ers to efficiently enforce fine-grained safety checks on third-party extensions without requiring their cooperation. Thisallows us to harness the true power of third-party softwareby giving it access to sensitive data while ensuring that itdoes not leak data.In this approach, a platform developer encapsulates allsafety checks in a policy class and selectively subjects ob-jects at risk to these policies. The runtime enforces thesepolicies simply by changing the types of these objects dy-namically. It uses the virtual method dispatch mechanismto substitute the original methods and operations with codelaced with safety checks efficiently. The runtime hides thetype changes from application code so the original code canrun unmodified.We have incorporated the notion of InvisiType into thePython language. We have applied the technique to 4 real-world Python web applications totaling 156,000 lines ofcode. InvisiType policies greatly enhance the security of theweb applications, including MoinMoin, a popular, 94,000-line Wiki Engine. MoinMoin has a large number of third-party extensions, which makes security enforcement impor-tant. With less than 150 lines of Python code, we found 16security bugs in MoinMoin. This represents a significantreduction in developers’ effort from a previous proposal,Flume, which required 1,000 lines of C++ code and modi-fications to 1,000 lines of Python code.Our InvisiType policies successfully found 19 cross-sitescripting vulnerabilities and 6 access control errors in total.The overhead of applying the policies is less than 4 percent,indicating that the technique is practical.1"
symp2010,A Security Evaluation of DNSSEC with NSEC3,"Domain Name System Security Extensions (DNSSEC) withHashed Authenticated Denial of Existence (NSEC3) is aprotocol slated for adoption by important parts of theDNS hierarchy, including the root zone, as a solution toDNS security vulnerabilities such as “cache-poisoning”attacks. We study the security goals and operation ofDNSSEC/NSEC3 and use Murϕ, a finite-state enumera-tion tool, to analyze its security guarantees and shortcom-ings. By checking DNSSEC/NSEC3 security properties inthe presence of a network attacker, we uncover severalweaknesses in the DNSSEC protocol, including incorrecttemporal dependencies in the DNSSEC signature attesta-tion chain and NSEC3 options that allow a forged nameto be inserted into a DNSSEC domain. We demonstratethe exploitability of the NSEC3 vulnerability by a browsercookie-stealing attack on a realistic laboratory DNSSECdomain. We offer implementation and configuration advicewhich minimize the exploitability of the uncovered vulnera-bilities. After re-incorporating the advised repairs into theMurϕ DNSSEC model, we demonstrate the updated proto-col no longer contains vulnerabilities exploitable within ourthreat model."
symp2010,On the Safety of Enterprise Policy Deployment,"Enterprise policy management is challenging and error-prone. Compared to existing work that focused on analyz-ing misconfigurations, our work is the first to address theissues that arose during policy deployment, i.e., effectingpolicy changes. In this paper, we demonstrate that naiveapproaches to policy deployment can easily create secu-rity vulnerabilities, such as granting access of sensitive re-sources to unprivileged users or temporarily allowing mali-cious traffic to critical network infrastructure. To systemat-ically solve this problem, we formally define secure and in-secure intermediate states, and further propose an efficientalgorithm to find a deployment procedure without insecureintermediate states. We implemented and evaluated our al-gorithm on Group Policy framework, while only harnessingexisting support and requiring no modification to the cur-rent infrastructure. Our evaluation shows that our solutionaddsminimal overhead to the overall deployment time whileprovably eliminating insecure intermediate states."
symp2010,Where Do You Want to Go Today? Escalating Privileges by Pathname Manipulation,"We analyze filename-based privilege escalation attacks,where an attacker creates filesystem links, thereby “trick-ing” a victim program into opening unintended files.We develop primitives for a POSIX environment, provid-ing assurance that files in “safe directories” (such as/etc/passwd) cannot be opened by looking up a file byan “unsafe pathname” (such as a pathname that resolvesthrough a symbolic link in a world-writable directory). Intoday’s UNIX systems, solutions to this problem are typ-ically built into (some) applications and use application-specific knowledge about (un)safety of certain directories.In contrast, we seek solutions that can be implemented inthe filesystem itself (or a library on top of it), thus providingprotection to all applications.Our solution is built around the concept of pathnamemanipulators, which are roughly the users that can influ-ence the result of a file lookup operation. For each user, wedistinguish unsafe pathnames from safe pathnames accord-ing to whether or not the pathname has any manipulatorsother than that user or root. We propose a safe-openprocedure that keeps track of the safety of the current path-name as it resolves it, and that takes extra precautions whileopening files with unsafe pathnames. We prove that our so-lution can prevent a common class of filename-based privi-lege escalation attacks, and describe our implementation ofthe safe-open procedure as a library function over thePOSIX filesystem interface. We tested our implementationon several UNIX variants to evaluate its implications forsystems and applications. Our experiments suggest that thissolution can be deployed in a portable way without break-ing existing systems, and that it is effective against this classof pathname resolution attacks.∗This work was supported in part by the Department of Homeland Se-curity under grant FA8750-08-2-0091."
symp2010,Joe-E: A Security-Oriented Subset of Java,"We present Joe-E, a language designed to support thedevelopment of secure software systems. Joe-E is a subsetof Java that makes it easier to architect and implement pro-grams with strong security properties that can be checkedduring a security review. It enables programmers to ap-ply the principle of least privilege to their programs; imple-ment application-specific reference monitors that cannot bebypassed; introduce and use domain-specific security ab-stractions; safely execute and interact with untrusted code;and build secure, extensible systems. Joe-E demonstrateshow it is possible to achieve the strong security propertiesof an object-capability language while retaining the fea-tures and feel of a mainstream object-oriented language.Additionally, we present ways in which Java’s static typesafety complements object-capability analysis and permitsadditional security properties to be verified statically, com-pared with previous object-capability languages which relyon runtime checks. In this paper, we describe the designand implementation of Joe-E and its advantages for secu-rity and auditability over standard Java. We demonstratehow Joe-E can be used to develop systems with novel secu-rity properties that would be difficult or impossible to en-sure otherwise, including a web application platform thatprovides transparent, transactional object persistence andcan safely host multiple mutually-distrustful applications ina single JVM."
symp2010,Preventing Capability Leaks in Secure JavaScript Subsets,"Publishers wish to sandbox third-party advertisementsto protect themselves from malicious advertisements. Onepromising approach, used by ADsafe, Dojo Secure, andJacaranda, sandboxes advertisements by statically verify-ing that their JavaScript conforms to a safe subset of thelanguage. These systems blacklist known dangerous proper-ties that would let advertisements escape the sandbox. Un-fortunately, this approach does not prevent advertisementsfrom accessing new methods added to the built-in prototypeobjects by the hosting page. In this paper, we show that one-third of the Alexa US Top 100 web sites would be exploitableby an ADsafe-verified advertisement. We propose an im-proved statically verified JavaScript subset that whitelistsknown-safe properties using namespaces. Our approachmaintains the expressiveness and performance of static ver-ification while improving security."
symp2010,Binary Code Extraction and Interface Identification for Security Applications,"Binary code reuse is the process of automatically identi-fying the interface and extracting the instructions anddata dependencies of a code fragment from an exe-cutable program, so that it is self-contained and can bereused by external code. Binary code reuse is useful fora number of security applications, including reusing theproprietary cryptographic or unpacking functions froma malware sample and for rewriting a network dialog.In this paper we conduct the first systematic study of au-tomated binary code reuse and its security applications.The main challenge in binary code reuse is under-standing the code fragment’s interface. We propose anovel technique to identify the prototype of an undoc-umented code fragment directly from the program’s bi-nary, without access to source code or symbol informa-tion. Further, we must also extract the code itself fromthe binary so that it is self-contained and can be easilyreused in another program. We design and implement atool that uses a combination of dynamic and static anal-ysis to automatically identify the prototype and extractthe instructions of an assembly function into a form thatcan be reused by other C code. The extracted functioncan be run independently of the rest of the program’sfunctionality and shared with other users.We apply our approach to scenarios that include ex-tracting the encryption and decryption routines frommalware samples, and show that these routines can bereused by a network proxy to decrypt encrypted traf-fic on the network. This allows the network proxy torewrite the malware’s encrypted traffic by combining theextracted encryption and decryption functions with thesession keys and the protocol grammar. We also showthat we can reuse a code fragment from an unpackingfunction for the unpacking routine for a different sampleof the same family, even if the code fragment is not acomplete function."
symp2010,Automatic Reverse Engineering of Data Structures from Binary Execution,"With only the binary executable of a program, it isuseful to discover the program’s data structures and infertheir syntactic and semantic definitions. Such knowledge ishighly valuable in a variety of security and forensic applica-tions. Although there exist efforts in program data structureinference, the existing solutions are not suitable for ourtargeted application scenarios. In this paper, we proposea reverse engineering technique to automatically revealprogram data structures from binaries. Our technique,called REWARDS, is based on dynamic analysis. Morespecifically, each memory location accessed by the programis tagged with a timestamped type attribute. Following theprogram’s runtime data flow, this attribute is propagatedto other memory locations and registers that share thesame type. During the propagation, a variable’s type getsresolved if it is involved in a type-revealing execution pointor “type sink”. More importantly, besides the forwardtype propagation, REWARDS involves a backward typeresolution procedure where the types of some previouslyaccessed variables get recursively resolved starting from atype sink. This procedure is constrained by the timestampsof relevant memory locations to disambiguate variables re-using the same memory location. In addition, REWARDS isable to reconstruct in-memory data structure layout basedon the type information derived. We demonstrate thatREWARDS provides unique benefits to two applications:memory image forensics and binary fuzzing for vulnerabil-ity discovery."
symp2010,Efficient Detection of Split Personalities in Malware,"Malware is the root cause of many security threats onthe Internet. To cope with the thousands of new malwaresamples that are discovered every day, security compa-nies and analysts rely on automated tools to extract theruntime behavior of malicious programs. Of course, mal-ware authors are aware of these tools and increasinglytry to thwart their analysis techniques. To this end, mal-ware code is often equipped with checks that look for ev-idence of emulated or virtualized analysis environments.When such evidence is found, the malware program be-haves differently or crashes, thus showing a different“personality” than on a real system.Recent work has introduced transparent analysis plat-forms (such as Ether or Cobra) that make it signif-icantly more difficult for malware programs to detecttheir presence. Others have proposed techniques to iden-tify and bypass checks introduced by malware authors.Both approaches are often successful in exposing theruntime behavior of malware even when the maliciouscode attempts to thwart analysis efforts. However, thesetechniques induce significant performance overhead, es-pecially for fine-grained analysis. Unfortunately, thismakes them unsuitable for the analysis of current high-volume malware feeds.In this paper, we present a technique that efficientlydetects when a malware program behaves differently inan emulated analysis environment and on an uninstru-mented reference host. The basic idea is simple: we justcompare the runtime behavior of a sample in our anal-ysis system and on a reference machine. However, ob-taining a robust and efficient comparison is very difficult.In particular, our approach consists of recording the in-teractions of the malware with the operating system inone run and using this information to deterministicallyreplay the program in our analysis environment. Our ex-periments demonstrate that, by using our approach, onecan efficiently detect malware samples that use a varietyof techniques to identify emulated analysis environments."
